{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:   /home/marco/github/numaware/joint_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "while os.getcwd() != \"/\" and \".gitignore\" not in os.listdir(os.getcwd()):\n",
    "\tos.chdir(\"..\")\n",
    "\tif os.getcwd() == \"/\":\n",
    "\t\tprint(\"COULD NOT FIND gitignore.  Invalid project base file.\")\n",
    "print(\"Current Working Directory:  \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.uafscs.utils.data_utils\t\tas dutils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m imgs_dir = \u001b[33m\"\u001b[39m\u001b[33m/usr/joint_model_data/processed_images_and_data/images\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m train_csv = \u001b[33m\"\u001b[39m\u001b[33m/usr/joint_model_data/processed_images_and_data/train_data.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_c_dataset = \u001b[43mdutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcartesian_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/numaware/joint_model/src/uafscs/utils/data_utils.py:71\u001b[39m, in \u001b[36mcartesian_dataset.__init__\u001b[39m\u001b[34m(self, imgs_pth, csv_file)\u001b[39m\n\u001b[32m     68\u001b[39m df = pd.read_csv(csv_file)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m.imgs_pth       = imgs_pth\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28mself\u001b[39m.carts          = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrList_to_floatList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcartesians\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m.yolo_midpoints = torch.tensor(strList_to_floatList(df[\u001b[33m\"\u001b[39m\u001b[33myolo_midpoint\u001b[39m\u001b[33m\"\u001b[39m],\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.our_midpoints  = torch.tensor(strList_to_floatList(df[\u001b[33m\"\u001b[39m\u001b[33mour_midpoint\u001b[39m\u001b[33m\"\u001b[39m],\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[31mValueError\u001b[39m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "imgs_dir = \"/usr/joint_model_data/processed_images_and_data/images\"\n",
    "train_csv = \"/usr/joint_model_data/processed_images_and_data/train_data.csv\"\n",
    "\n",
    "train_c_dataset = dutils.cartesian_dataset(imgs_dir,train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,ym , om , c=train_c_dataset.__get_item__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([145.5800,  27.3000,  19.8100,  60.6500, -68.1400,  53.6400])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>joints</th>\n",
       "      <th>cartesians</th>\n",
       "      <th>yolo_midpoint</th>\n",
       "      <th>our_midpoint</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>motionblur/img63_motionblur.png</td>\n",
       "      <td>[145.58, 27.3, 19.81, 60.65, -68.14, 53.64]</td>\n",
       "      <td>[[-315.97, 287.07, 358.95], [0.01, 0.009, -0.6...</td>\n",
       "      <td>[182.071, 98.001]</td>\n",
       "      <td>[182.96, 129.976]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img26.png</td>\n",
       "      <td>[77.94, 38.12, 48.33, -13.6, -88.66, 90.88]</td>\n",
       "      <td>[[51.4, 321.52, 207.99], [0.01, 0.009, -0.694,...</td>\n",
       "      <td>[458.675, 210.644]</td>\n",
       "      <td>[465.457, 234.5]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saltandpepper/img88_saltandpepper.png</td>\n",
       "      <td>[123.26, 39.96, 45.61, 31.71, -88.35, 87.73]</td>\n",
       "      <td>[[-148.09, 294.77, 203.89], [0.01, 0.009, -0.6...</td>\n",
       "      <td>[322.44, 221.866]</td>\n",
       "      <td>[325.621, 251.92]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>posterize/img72_posterize.png</td>\n",
       "      <td>[117.7, 37.66, 52.5, 26.17, -92.25, 90.12]</td>\n",
       "      <td>[[-110.78, 279.2, 204.21], [0.01, 0.009, -0.69...</td>\n",
       "      <td>[349.762, 221.971]</td>\n",
       "      <td>[353.899, 249.37]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>defocus/img119_defocus.png</td>\n",
       "      <td>[114.79, 2.32, 50.42, 27.65, -58.23, 73.73]</td>\n",
       "      <td>[[-106.51, 298.42, 364.42], [0.01, 0.009, -0.6...</td>\n",
       "      <td>[353.255, 96.369]</td>\n",
       "      <td>[357.637, 123.855]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     img  \\\n",
       "0        motionblur/img63_motionblur.png   \n",
       "1                              img26.png   \n",
       "2  saltandpepper/img88_saltandpepper.png   \n",
       "3          posterize/img72_posterize.png   \n",
       "4             defocus/img119_defocus.png   \n",
       "\n",
       "                                         joints  \\\n",
       "0   [145.58, 27.3, 19.81, 60.65, -68.14, 53.64]   \n",
       "1   [77.94, 38.12, 48.33, -13.6, -88.66, 90.88]   \n",
       "2  [123.26, 39.96, 45.61, 31.71, -88.35, 87.73]   \n",
       "3    [117.7, 37.66, 52.5, 26.17, -92.25, 90.12]   \n",
       "4   [114.79, 2.32, 50.42, 27.65, -58.23, 73.73]   \n",
       "\n",
       "                                          cartesians       yolo_midpoint  \\\n",
       "0  [[-315.97, 287.07, 358.95], [0.01, 0.009, -0.6...   [182.071, 98.001]   \n",
       "1  [[51.4, 321.52, 207.99], [0.01, 0.009, -0.694,...  [458.675, 210.644]   \n",
       "2  [[-148.09, 294.77, 203.89], [0.01, 0.009, -0.6...   [322.44, 221.866]   \n",
       "3  [[-110.78, 279.2, 204.21], [0.01, 0.009, -0.69...  [349.762, 221.971]   \n",
       "4  [[-106.51, 298.42, 364.42], [0.01, 0.009, -0.6...   [353.255, 96.369]   \n",
       "\n",
       "         our_midpoint  class  \n",
       "0   [182.96, 129.976]    2.0  \n",
       "1    [465.457, 234.5]    1.0  \n",
       "2   [325.621, 251.92]    1.0  \n",
       "3   [353.899, 249.37]    1.0  \n",
       "4  [357.637, 123.855]    1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "series = df[\"joints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
